{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Base object for all inputs and outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, grad):\n",
    "        self.value = value\n",
    "        self.gradient = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyNode(object):\n",
    "    \"\"\"\n",
    "    Multiplies two inputs\n",
    "    \"\"\"\n",
    "    def forward(self, *args):\n",
    "        self.inputs = []\n",
    "        \n",
    "        for i in args:\n",
    "            self.inputs.append(i)\n",
    "        \n",
    "        self.output = Node(self.inputs[0].value * self.inputs[1].value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inputs[0].gradient = self.inputs[1].value * self.output.gradient\n",
    "        self.inputs[1].gradient = self.inputs[0].value * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNode(object):    \n",
    "    \"\"\"\n",
    "    Adds two inputs x1 and x2.\n",
    "    \"\"\"\n",
    "    def forward(self, nodes):\n",
    "        self.inputs = nodes\n",
    "             \n",
    "        self.output = Node(self.inputs[0].value + self.inputs[1].value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inputs[0].gradient = 1 * self.output.gradient\n",
    "        self.inputs[1].gradient = 1 * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidNode(object):\n",
    "    \"\"\"\n",
    "    Adds a sigmoid non-linearity to a single input\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.output = Node(1/(1 + np.exp(-1 * self.x.value)), 0.0)\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self):\n",
    "        s = 1/(1 + np.exp(-1 * self.x.value))\n",
    "        self.x.gradient = (s * (1 - s)) * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, alpha =0.01,x1 = 0,x2=0, **kwargs):\n",
    "        ### Hyper parameters\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        ### Set inputs\n",
    "        self.inputs = [Node(x1,0.0),Node(x2,0.0)]\n",
    "        \n",
    "        for i in kwargs:\n",
    "            input = Node(kwargs[i],0.0)\n",
    "            self.inputs.append(input)\n",
    "        \n",
    "        ### Initializing weights to a random float between -1 and 1\n",
    "        self.weights = []\n",
    "        for i in self.inputs:\n",
    "            weight = Node(np.random.uniform(-1,1),0.0)\n",
    "            self.weights.append(weight) \n",
    "        \n",
    "        ### Initialize bias (just one for now) to a random float between -1 and 1\n",
    "        self.bias = Node(np.random.uniform(-1,1),0.0)\n",
    "        \n",
    "        ### Initialize Operators\n",
    "        self.initialize_operators()\n",
    "        \n",
    "    def initialize_operators(self):\n",
    "        ### Multiply inputs with weights operator\n",
    "        self.weighted_input_mult_op =[]\n",
    "        for i in range(len(self.inputs)):\n",
    "            self.weighted_input_mult_op.append(MultiplyNode())\n",
    "            \n",
    "        ### Add all weighted inputs operator\n",
    "        self.sum_of_all_weighted_inputs_op = AddNode()\n",
    "        \n",
    "        ### Add bias to the sum of all weighted inputs operator\n",
    "        self.sum_of_weighted_inputs_and_bias_op = AddNode()\n",
    "        \n",
    "        ### Sigmoid\n",
    "        self.sigmoid = SigmoidNode()\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "                ### Multiply inputs with weights\n",
    "        self.weighted_inputs = []\n",
    "        for i in range(len(self.weighted_input_mult_op)):            \n",
    "            input_mul_weight = self.weighted_input_mult_op[i].forward(self.inputs[i],self.weights[i])\n",
    "            self.weighted_inputs.append(input_mul_weight)\n",
    "               \n",
    "        \n",
    "        ### Add all weighted inputs\n",
    "        self.sum_of_all_weighted_inputs = self.sum_of_all_weighted_inputs_op.forward(self.weighted_inputs)\n",
    "            \n",
    "        \n",
    "        ### Add bias to the sum of all weighted inputs\n",
    "        self.sum_of_weighted_inputs_and_bias = self.sum_of_weighted_inputs_and_bias_op.forward([self.sum_of_all_weighted_inputs,self.bias])\n",
    "        \n",
    "        self.sigmoid.forward(self.sum_of_weighted_inputs_and_bias)\n",
    "        \n",
    "    \n",
    "    def backward(self):\n",
    "        self.sigmoid.backward()\n",
    "        self.sum_of_weighted_inputs_and_bias_op.backward()\n",
    "        self.sum_of_all_weighted_inputs_op.backward()\n",
    "        for i in range(len(self.weighted_inputs)):\n",
    "            self.weighted_input_mult_op[i].backward()\n",
    "            \n",
    "    def update(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i].value -= self.alpha * self.weights[i].gradient\n",
    "            \n",
    "        self.bias.value -= self.alpha * self.bias.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3481972639817001"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron(alpha = 0.2, x1 = 2, x2 = 3)\n",
    "\n",
    "# number of iterations\n",
    "N = 100000\n",
    "# expected output \n",
    "target = 0.3481972639817\n",
    "\n",
    "for i in range(N):\n",
    "    # Step 1. Forward Pass\n",
    "    p.forward()\n",
    "    # Step 2. Calculate Loss. -2 * (y - output) is the gradient of output w.r.t \n",
    "    # square loss function.\n",
    "    p.sigmoid.output.gradient = -2 * (target - p.sigmoid.output.value)\n",
    "    # Step 3. Backward Pass\n",
    "    p.backward()\n",
    "    # Step 4. Update Weights and Bias\n",
    "    p.update()\n",
    "\n",
    "p.sigmoid.output.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
